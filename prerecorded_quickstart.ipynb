{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript JSON file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "from deepgram import DeepgramClient, PrerecordedOptions, FileSource\n",
    "\n",
    "# Deepgram API key (consider using an environment variable in production)\n",
    "DG_KEY = \"223e1fd61bfc117a1416cbf50bb93a25ac31b731\"\n",
    "\n",
    "# Local path to the audio file\n",
    "AUDIO_FILE_PATH = \"ReelAudio-47345.mp3\"\n",
    "\n",
    "# Path to save the transcript JSON file\n",
    "TRANSCRIPT_FILE = \"transcript.json\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Create a Deepgram client using the API key\n",
    "        deepgram = DeepgramClient(DG_KEY)\n",
    "\n",
    "        # Read local audio file as bytes\n",
    "        with open(AUDIO_FILE_PATH, \"rb\") as f:\n",
    "            audio_bytes = f.read()\n",
    "\n",
    "        payload: FileSource = {\n",
    "            \"buffer\": audio_bytes,\n",
    "            \"mimetype\": \"audio/mpeg\",  # MP3 mimetype\n",
    "        }\n",
    "\n",
    "        options = PrerecordedOptions(\n",
    "            model=\"nova-2\",\n",
    "            smart_format=True,\n",
    "        )\n",
    "\n",
    "        response = deepgram.listen.rest.v(\"1\").transcribe_file(payload, options)\n",
    "\n",
    "        with open(TRANSCRIPT_FILE, \"w\", encoding=\"utf-8\") as transcript_file:\n",
    "            transcript_file.write(response.to_json(indent=4))\n",
    "\n",
    "        print(\"Transcript JSON file generated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe any audio file with Deepgram!\n",
    "\n",
    "**Make a copy of this notebook into your own drive, and follow the instructions below!** ðŸ¥³ðŸ¥³ðŸ¥³\n",
    "\n",
    "\n",
    "----------------------------\n",
    "\n",
    "# Get started:\n",
    "Running the following three cells will allow you to transcribe any audio you wish. The comments below point out the variables you can manipulate to modify your output as you wish.\n",
    "\n",
    "Before running this notebook, you'll need to have a couple audio files on-hand\n",
    "that you wish to transcribe. Once you have those files in a folder, you should be able to transcribe as you please. Just specify the filepaths as outlined below!\n",
    "\n",
    "And by the way, if you haven't yet signed up for Deepgram, check out this link here: https://dpgr.am/prerecorded-notebook-signup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Dependencies\n",
    "\n",
    "Run this cell to download all necessary dependencies.\n",
    "\n",
    "Note: You can run a cell by clicking the play button on the left or by clicking on the cell and pressing `shift`+`ENTER` at the same time. (Or `shift` + `return` on Mac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.4)\n",
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2025.6.15)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: future, ffmpeg-python\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [ffmpeg-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ffmpeg-python-0.2.0 future-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting deepgram-sdk\n",
      "  Downloading deepgram_sdk-4.8.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.12/site-packages (from deepgram-sdk) (0.28.1)\n",
      "Requirement already satisfied: websockets>=12.0 in ./.venv/lib/python3.12/site-packages (from deepgram-sdk) (15.0.1)\n",
      "Requirement already satisfied: dataclasses-json>=0.6.3 in ./.venv/lib/python3.12/site-packages (from deepgram-sdk) (0.6.7)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in ./.venv/lib/python3.12/site-packages (from deepgram-sdk) (4.14.0)\n",
      "Requirement already satisfied: aiohttp>=3.9.1 in ./.venv/lib/python3.12/site-packages (from deepgram-sdk) (3.12.12)\n",
      "Collecting aiofiles>=23.2.1 (from deepgram-sdk)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aenum>=3.1.0 (from deepgram-sdk)\n",
      "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting deprecation>=2.1.0 (from deepgram-sdk)\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.9.1->deepgram-sdk) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json>=0.6.3->deepgram-sdk) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json>=0.6.3->deepgram-sdk) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.6.3->deepgram-sdk) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.6.3->deepgram-sdk) (1.1.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx>=0.25.2->deepgram-sdk) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.25.2->deepgram-sdk) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.25.2->deepgram-sdk) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->deepgram-sdk) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->deepgram-sdk) (1.3.1)\n",
      "Downloading deepgram_sdk-4.8.1-py3-none-any.whl (157 kB)\n",
      "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: aenum, deprecation, aiofiles, deepgram-sdk\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [deepgram-sdk][0m [deepgram-sdk]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aenum-3.1.16 aiofiles-24.1.0 deepgram-sdk-4.8.1 deprecation-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2025.6.15)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install requests ffmpeg-python\n",
    "! pip install deepgram-sdk --upgrade\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Upload audio files to this Colab!\n",
    "\n",
    "On the left, you'll see a side-bar with a folder icon. Click that icon, and you'll see a series of folders. This is where you'll upload your audio files.\n",
    "\n",
    "You can upload your files directly into this directory by clicking the upload icon in the top left. The icon looks like a sheet of paper with an upwards-pointing arrow on it.\n",
    "\n",
    "Click the upload icon and select the audio file you wish to transcribe. It will take a few moments for the audio to appear, but once it does, move onto Step 3.\n",
    "\n",
    "(We have added an example audio, `preamble.wav` to this project.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have you completed Step 2 above? ðŸ‘€\n",
    "# Do you see your audio file in the folder on the left? ðŸ“‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Transcription\n",
    "\n",
    "Fill in the following variables:\n",
    "\n",
    "\n",
    "* `DG_KEY` = Your personal Deepgram API key\n",
    "* `AUDIO_FILE_URL` = a URL for an audio file you wish to transcribe.\n",
    "\n",
    "\n",
    "Now run the cell! (`Shift` + `Enter`)\n",
    "\n",
    "-----------\n",
    "\n",
    "\n",
    "\n",
    "And by the way, if you're already a Deepgram user, and you're getting an error in this cell the most common fixes are:\n",
    "\n",
    "1. You may need to update your installation of the deepgram-sdk.\n",
    "2. You may need to check how many credits you have left in your Deepgram account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: DeepgramApiError: Bad Request: failed to process audio: corrupt or unsupported data (Status: 400)\n"
     ]
    }
   ],
   "source": [
    "from deepgram import DeepgramClient, PrerecordedOptions, FileSource\n",
    "\n",
    "# Deepgram API key (consider using an environment variable in production)\n",
    "DG_KEY = \"223e1fd61bfc117a1416cbf50bb93a25ac31b731\"\n",
    "\n",
    "# Local path to the audio file\n",
    "AUDIO_FILE_PATH = \"ReelAudio-47345.mp3\"\n",
    "\n",
    "# Path to save the transcript JSON file\n",
    "TRANSCRIPT_FILE = \"transcript.json\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Create a Deepgram client using the API key\n",
    "        deepgram = DeepgramClient(DG_KEY)\n",
    "\n",
    "        # Read local audio file as bytes\n",
    "        with open(AUDIO_FILE_PATH, \"rb\") as f:\n",
    "            audio_bytes = f.read()\n",
    "\n",
    "        payload: FileSource = {\n",
    "            \"buffer\": audio_bytes,\n",
    "            \"mimetype\": \"audio/mpeg\",  # MP3 mimetype\n",
    "        }\n",
    "\n",
    "        options = PrerecordedOptions(\n",
    "            model=\"nova-2\",\n",
    "            smart_format=True,\n",
    "        )\n",
    "\n",
    "        response = deepgram.listen.rest.v(\"1\").transcribe_file(payload, options)\n",
    "\n",
    "        with open(TRANSCRIPT_FILE, \"w\", encoding=\"utf-8\") as transcript_file:\n",
    "            transcript_file.write(response.to_json(indent=4))\n",
    "\n",
    "        print(\"Transcript JSON file generated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If the cell above succeeds, you should see JSON output file(s) in the same directory\n",
    "as your audio files. Note: There may be a small delay between when\n",
    "the cell finishes running and when the JSON file actually appears.\n",
    "This is normal. Just wait a few moments for the JSONs to appear.\n",
    "It should take less than a minute, depending on the size of your file(s).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Check out your transcription!\n",
    "\n",
    "The function below parses the output JSON and prints out the pure transcription of one of the files you just transcribed! (Make sure\n",
    "the file you're trying to examine is indeed already loaded into the\n",
    "folder on the left!)\n",
    "\n",
    "**Set the `OUTPUT` variable to the name of the file you wish to see the transcription of.**\n",
    "\n",
    "Then run this cell (`Shift`+`Enter`) to see a sentence-by-sentence transcription of your audio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Rahman, good morning.\n",
      " Good morning.\n",
      " Rahman, this is Saad.\n",
      " I'm calling you from HOS.\n",
      " Is this a good time to speak to you? We can have this call after an hour.\n",
      " An hour? Okay.\n",
      " I'll give you a callback in an hour.\n",
      " Just so that I'm calling regarding content in social media.\n",
      " I'm not really sure if you guys need it.\n",
      " So do I call you back after an hour? Yeah.\n",
      " Yeah.\n",
      " We will have this call.\n",
      " Alright.\n",
      " Awesome.\n",
      " I'll give you a callback in an hour.\n",
      " Thanks.\n",
      " By the way, someone tells you to call back after an hour, make sure you check their intent because there's no point of calling back unless they actually have a requirement.\n",
      " Just wanna know, is this something you're even looking for? I don't wanna waste your time.\n",
      " That makes it more real.\n",
      " So check.\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Set this variable to the path of the output file you wish to read\n",
    "OUTPUT = 'transcript.json'\n",
    "\n",
    "\n",
    "# The JSON is loaded with information, but if you just want to read the\n",
    "# transcript, run the code below!\n",
    "def print_transcript(transcription_file):\n",
    "  with open(transcription_file, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        result = data['results']['channels'][0]['alternatives'][0]['transcript']\n",
    "        result = result.split('.')\n",
    "        for sentence in result:\n",
    "          print(sentence + '.')\n",
    "\n",
    "print_transcript(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
